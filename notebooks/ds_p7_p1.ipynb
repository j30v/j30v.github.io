{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P7_feature_tool.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtkDKmyojJ4i",
        "outputId": "f39c63b4-6319-4ed8-8ad6-1356b9083ac5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxXS5tGyjRYG"
      },
      "source": [
        "# install dependencies\n",
        "!pip install dask\n",
        "!pip install featuretools\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q36-yfa5jV23",
        "outputId": "500c5d57-7342-40fc-9d75-3d64c4bbfa78"
      },
      "source": [
        "# clean workspace\n",
        "!rm -rf top_features\n",
        "!rm -rf data\n",
        "!rm -rf partitioned_data\n",
        "!rm data.zip\n",
        "!rm -rf __MACOSX\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'data.zip': No such file or directory\n",
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xBu3lJUxjZYP",
        "outputId": "879f3048-e260-4258-dd7a-fd3c8e6c997e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from random import sample\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import featuretools as ft\n",
        "ft.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.26.2'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL-7GHOhjc5E"
      },
      "source": [
        "path = '/content/drive/MyDrive/Notebook/data_scientist/P7/'\n",
        "list_files = os.listdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mtt2jrL_jG52",
        "outputId": "0721e996-9d47-4ba4-af11-f93e37681a0b"
      },
      "source": [
        "print('Reading in data')\n",
        "\n",
        "# Read in the full datasets\n",
        "app_train = pd.read_csv(path + 'application_train.csv')\n",
        "bureau = pd.read_csv(path + 'bureau.csv')\n",
        "bureau_balance = pd.read_csv(path + 'bureau_balance.csv')\n",
        "cash = pd.read_csv(path + 'POS_CASH_balance.csv')\n",
        "credit = pd.read_csv(path + 'credit_card_balance.csv')\n",
        "previous = pd.read_csv(path + 'previous_application.csv')\n",
        "installments = pd.read_csv(path + 'installments_payments.csv')\n",
        "\n",
        "# Join the application dataframes together\n",
        "app_train['set'] = 'train'\n",
        "\n",
        "# Append the dataframes (this is a row bind in R)\n",
        "app = app_train\n",
        "\n",
        "# Create the entity set with an id\n",
        "es = ft.EntitySet(id = 'applications')\n",
        "\n",
        "# Add in all the entities\n",
        "\n",
        "# Entities with a unique index\n",
        "es = es.entity_from_dataframe(entity_id = 'app', dataframe = app, index = 'SK_ID_CURR')\n",
        "\n",
        "es = es.entity_from_dataframe(entity_id = 'bureau', dataframe = bureau, index = 'SK_ID_BUREAU')\n",
        "\n",
        "es = es.entity_from_dataframe(entity_id = 'previous', dataframe = previous, index = 'SK_ID_PREV')\n",
        "\n",
        "# Entities that do not have a unique index\n",
        "es = es.entity_from_dataframe(entity_id = 'bureau_balance', dataframe = bureau_balance, \n",
        "                              make_index = True, index = 'bb_index')\n",
        "\n",
        "es = es.entity_from_dataframe(entity_id = 'cash', dataframe = cash, \n",
        "                              make_index = True, index = 'cash_index')\n",
        "\n",
        "es = es.entity_from_dataframe(entity_id = 'installments', dataframe = installments,\n",
        "                              make_index = True, index = 'in_index')\n",
        "\n",
        "es = es.entity_from_dataframe(entity_id = 'credit', dataframe = credit,\n",
        "                              make_index = True, index = 'credit_index')\n",
        "\n",
        "\n",
        "# Relationship between app and bureau\n",
        "r_app_bureau = ft.Relationship(es['app']['SK_ID_CURR'], es['bureau']['SK_ID_CURR'])\n",
        "\n",
        "# Relationship between bureau and bureau balance\n",
        "r_bureau_balance = ft.Relationship(es['bureau']['SK_ID_BUREAU'], es['bureau_balance']['SK_ID_BUREAU'])\n",
        "\n",
        "# Relationship between current app and previous apps\n",
        "r_app_previous = ft.Relationship(es['app']['SK_ID_CURR'], es['previous']['SK_ID_CURR'])\n",
        "\n",
        "# Relationships between previous apps and cash, installments, and credit\n",
        "r_previous_cash = ft.Relationship(es['previous']['SK_ID_PREV'], es['cash']['SK_ID_PREV'])\n",
        "r_previous_installments = ft.Relationship(es['previous']['SK_ID_PREV'], es['installments']['SK_ID_PREV'])\n",
        "r_previous_credit = ft.Relationship(es['previous']['SK_ID_PREV'], es['credit']['SK_ID_PREV'])\n",
        "\n",
        "# Add in the defined relationships\n",
        "es = es.add_relationships([r_app_bureau, r_bureau_balance, r_app_previous,\n",
        "                           r_previous_cash, r_previous_installments, r_previous_credit])\n",
        "                           \n",
        "print(es)\n",
        "                           \n",
        "print('Clearing up memory')\n",
        "\n",
        "gc.enable()\n",
        "# Clear up memory\n",
        "del app, bureau, bureau_balance, cash, credit, installments, previous\n",
        "gc.collect()\n",
        "\n",
        "print('Deep Feature Synthesis in Progress')\n",
        "\n",
        "# Default primitives from featuretools\n",
        "default_agg_primitives =  [\"sum\", \"std\", \"max\", \"skew\", \"min\", \"mean\", \"count\", \"percent_true\", \"num_unique\", \"mode\"]\n",
        "default_trans_primitives =  [\"day\", \"year\", \"month\", \"weekday\", \"haversine\", \"num_words\", \"num_characters\"]\n",
        "\n",
        "# DFS for application features using a max depth of 1\n",
        "feature_matrix, feature_names = ft.dfs(entityset = es, target_entity = 'app',\n",
        "                       trans_primitives = default_trans_primitives,\n",
        "                       agg_primitives=default_agg_primitives, \n",
        "                       max_depth = 1, features_only=False, verbose = True)\n",
        "                       \n",
        "# Reset the index to make SK_ID_CURR a column again                                      \n",
        "feature_matrix = feature_matrix.reset_index()\n",
        "\n",
        "print('Saving features')\n",
        "feature_matrix.to_csv('/content/drive/MyDrive/Notebook/data_scientist/P7/feature_matrix.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading in data\n",
            "Entityset: applications\n",
            "  Entities:\n",
            "    app [Rows: 307511, Columns: 123]\n",
            "    bureau [Rows: 1716428, Columns: 17]\n",
            "    previous [Rows: 1670214, Columns: 37]\n",
            "    bureau_balance [Rows: 27299925, Columns: 4]\n",
            "    cash [Rows: 10001358, Columns: 9]\n",
            "    installments [Rows: 13605401, Columns: 9]\n",
            "    credit [Rows: 3840312, Columns: 24]\n",
            "  Relationships:\n",
            "    bureau.SK_ID_CURR -> app.SK_ID_CURR\n",
            "    bureau_balance.SK_ID_BUREAU -> bureau.SK_ID_BUREAU\n",
            "    previous.SK_ID_CURR -> app.SK_ID_CURR\n",
            "    cash.SK_ID_PREV -> previous.SK_ID_PREV\n",
            "    installments.SK_ID_PREV -> previous.SK_ID_PREV\n",
            "    credit.SK_ID_PREV -> previous.SK_ID_PREV\n",
            "Clearing up memory\n",
            "Deep Feature Synthesis in Progress\n",
            "Built 348 features\n",
            "Elapsed: 36:20 | Progress: 100%|██████████\n",
            "Saving features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuLxUyhIopEp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}